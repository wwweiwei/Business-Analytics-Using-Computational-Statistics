---
title: "BACS HW (Week 5)"
author: '106070038'
output:
  html_document: default
  PDF: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Question 1
##### a. Given the critical DOI score that Google uses to detect malicious apps (-3.7), what is the probability that a randomly chosen app from Google’s app store will turn off the Verify security feature?


- Answer: 0.0001077997

```{r fig.width = 6, fig.height = 4.5}
pnorm(-3.7)
```

##### b. Assuming there were ~2.2 million apps when the article was written, what number of apps on the Play Store did Google expect would maliciously turn off the Verify feature once installed?

- Answer: 

  - 2.2 millions = 22,000,000
  - 22,000,000 * 0.0001077997 = 2371.593
  - **About 2372 apps**
  
```{r}
malicious_N = 22000000 * 0.0001077997
malicious_N
```

### Question 2
##### a. The Null distribution of t-values:
(i.) Visualize the distribution of Verizon’s repair times, marking the mean with a vertical line
```{r fig.width = 6, fig.height = 4.5}
set.seed(5)
library(readr)
verizon <- read_csv("verizon.csv")
plot(density(verizon$Time), lwd = 2, main = "Density plot of time")
abline(v = mean(verizon$Time), col = "blue", lwd = 3)
mean(verizon$Time)
```

(ii.) Given what PUC wishes to test, how would you write the hypothesis? (not graded)

- Answer: 

  - H0: $\mu =$ 7.6

  - H1: $\mu \neq$ 7.6

(iii.) Estimate the population mean, and the 99% confidence interval (CI) of this estimate

- df>30

```{r }
set.seed(5)

v_x_bar <- mean(verizon$Time)
v_sd <- sd(verizon$Time)
v_se <- v_sd/sqrt(length(verizon$Time))
CI_upper_bound <- v_x_bar + 2.58*v_se
CI_lower_bound <- v_x_bar - 2.58*v_se

cat("99% confidence interval of population mean =>", CI_lower_bound, " ", CI_upper_bound)
```

(iv.) Using the traditional statistical testing methods we saw in class, find the t-statistic and p-value of the test
```{r }
set.seed(5)
avg_time_hypo <- 7.6
time_sample <- verizon$Time
sample_size <- length(time_sample) 
sample_mean <- mean(time_sample) 
sample_sd <- sd(time_sample)

# standard error
se <- (sample_sd /sqrt(sample_size))
# t-statistic
t <- (sample_mean - avg_time_hypo) / se
# p-value
df <- sample_size - 1 
p <- 1 - pt(t, df)

cat(" sample size =",sample_size, ", mean of sample =", sample_mean, "\n","standard deviation of sample =",sample_sd, ", standard error of sample =", se, "\n","**Answer:","\n","t-statistic =",t, ", p-value =", p )
```

(v.) Briefly describe how these values relate to the Null distribution of t (not graded)

- Answer: 

  -  t-statistic: t-values are an example of what statisticians call test statistics. A test statistic is a standardized value that is calculated from sample data during a hypothesis test. The procedure that calculates the test statistic compares your data to what is expected under the null hypothesis. **Each type of t-test uses a specific procedure to boil all of your sample data down to one value, the t-value. The calculations behind t-values compare your sample means to the null hypothesis and incorporates both the sample size and the variability in the data.** A t-value of 0 indicates that the sample results exactly equal the null hypothesis. **As the difference between the sample data and the null hypothesis increases, the absolute value of the t-value increases.**

  -  p-value: In null hypothesis significance testing, the p-value is the probability of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypothesis is correct. **A very small p-value means that such an extreme observed outcome would be very unlikely under the null hypothesis.**

  - Reference: 
    https://blog.minitab.com/en/adventures-in-statistics-2/understanding-t-tests-t-values-and-t-distributions
    https://en.wikipedia.org/wiki/P-value
  
(vi.) What is your conclusion about the advertising claim from this t-statistic, and why?

- Answer: There are **2.56 standard errors($S_\bar{x}$)** from the hypothesized mean($\mu_0$) to sample mean($\bar{x}$), because $t-statistic = \dfrac{(\bar{x}-\mu_0)}{S_\bar{x}}$.

##### b. Let’s use bootstrapping on the sample data to examine this problem:
(i.) Bootstrapped Percentile: Estimate the bootstrapped 99% CI of the mean

- bootstrap the population mean for **2000 times**

```{r }
set.seed(5)
boot_mean <- function(sample0) {
  resample <- sample(sample0, length(verizon$Time), replace=TRUE) 
  return(mean(resample))
}
num_boots <- 2000
mean_boots <- replicate(num_boots, boot_mean(verizon$Time))
pop_mean_ci_99 <- quantile(mean_boots, probs=c(0.005, 0.995))
cat("99% confidence interval of mean => ", pop_mean_ci_99)
```

(ii.) Bootstrapped Difference of Means: What is the 99% CI of the bootstrapped difference between the population mean and the hypothesized mean?

```{r }
set.seed(5)
time_hypo <- 7.6

boot_mean_diffs <- function(sample0, mean_hyp) {
  resample <- sample(sample0, length(sample0), replace=TRUE) 
  return( mean(resample) - mean_hyp )
}

num_boots <- 2000
mean_diffs_boots <- replicate(num_boots, boot_mean_diffs(verizon$Time, time_hypo) )
diff_ci_99 <- quantile(mean_diffs_boots, probs=c(0.005, 0.995))
cat("99% CI of difference between the population mean and the hypothesized mean =>", diff_ci_99)
```

(iii.) Bootstrapped t-Interval: What is 99% CI of the bootstrapped t-statistic?

```{r }
set.seed(5)
boot_t_stat <- function(sample0, mean_hyp) {
  resample <- sample(sample0, length(sample0), replace=TRUE) 
  diff <- mean(resample) - mean_hyp
  se <- sd(resample)/sqrt(length(resample))
  return( diff / se )
}

time_hypo <- 7.6
num_boots <- 2000
t_boots <- replicate(num_boots, boot_t_stat(verizon$Time, time_hypo))
# mean(t_boots)
t_ci_99 <- quantile(t_boots, probs=c(0.005, 0.995))
cat("99% CI of the bootstrapped t-statistic =>", t_ci_99)
```

(iv.) Plot separate distributions of all three bootstraps above (for ii and iii make sure to include zero on the x-axis)

- i. Bootstrapped 99% CI of the mean

```{r fig.width = 5, fig.height = 3.5}
plot(density(mean_boots), col="blue", main="Plot of bootstrapped mean", lwd=2)
abline(v=mean(mean_boots))
abline(v=pop_mean_ci_99, lty="dashed")
```

- ii. Bootstrapped difference between the population mean and the hypothesized mean

```{r fig.width = 5, fig.height = 3.5}
plot(density(mean_diffs_boots), col="blue", main="Plot of bootstrapped mean difference", lwd=2)
abline(v=mean(mean_diffs_boots))
abline(v=diff_ci_99, lty="dashed")
```

- iii. Bootstrapped t-statistic

```{r fig.width = 5, fig.height = 3.5}
plot(density(t_boots), col="blue", main="Standardized mean difference", lwd=2)
abline(v=mean(t_boots))
abline(v=t_ci_99, lty="dashed")
```

##### c. Do the four methods (traditional test, bootstrapped percentile, bootstrapped difference of means, bootstrapped t-Interval) agree with each other on the test?

- Answer: Yes, because the **shape** of plot in bootstrapped percentile, bootstrapped difference of means and  bootstrapped t-Interval are the same. The only difference is the **scale**. Besides, the t-statistic(2.560762) is in the t_ci_99 and p(0.005265342) is smaller than 0.01. 

