---
title: "BACS HW (Week 4)"
author: '106070038'
output:
  html_document: default
  PDF: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r fig.width = 5, fig.height = 3.7}
set.seed(1)
```

### Question 1) Let’s reexamine what it means to standardize data. To standardize a vector, subtract the mean of the vector from all its values, and then divide them by the standard deviation.
a) Create a normal distribution (mean=940, sd=190) and standardize it (let’s call it rnorm_std) <br>
i. What should we expect the mean and standard deviation of rnorm_std to be, and why?

```{r fig.width = 5, fig.height = 3.7}
rnorm_ <- rnorm(n=100000, mean=940, sd=190)

standardized <- function(numbers) {
  numbers <- (numbers - mean(numbers)) / sd(numbers)
  return(numbers)
}
rnorm_std <- standardized(rnorm_)
mean_rnorm_std <- mean(rnorm_std)

# print the answer
cat("mean:", mean(rnorm_std), "\n")
cat("sd:", sd(rnorm_std), "\n")
```
- Answer: After standardized, the mean should be close to 0 and the sd should be close to 1.
<br>

ii) What should the distribution (shape) of rnorm_std look like, and why?
```{r fig.width = 5, fig.height = 3.7}
plot(density(rnorm_std), col="blue", lwd=2, main = "Distribution of rnorm_std")
```

- Answer: After standardized, the distribution is close to a **normal distribution**. 
<br>

iii) What do we generally call distributions that are normal and standardized?
- Answer: A normal distribution is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function is
$$
f(x)=\dfrac{1}{\sigma\sqrt{2\pi}} e^{-\dfrac{1}{2}(\dfrac{x-\mu}{\sigma})^2}\\
$$
- Answer: Every normal distribution is a version of the standard normal distribution. if X is a normal deviate with parameters $\mu$ and $\sigma ^2$, then this X distribution can be re-scaled and shifted via the formula $$Z = \dfrac{(X−\mu)}{\sigma}$$
 to convert it to the "standard" normal distribution. This variate is also called the **standardized form of X**.
- Ref: https://en.wikipedia.org/wiki/Normal_distribution
<br>

(b) Create a standardized version of minday discussed in question 3 (let’s call it minday_std)
```{r fig.width = 5, fig.height = 3.7}
bookings <- read.table("first_bookings_datetime_sample.txt", header=TRUE)
hours  <- as.POSIXlt(bookings$datetime, format="%m/%d/%Y %H:%M")$hour
mins   <- as.POSIXlt(bookings$datetime, format="%m/%d/%Y %H:%M")$min
minday <- hours*60 + mins

standardized <- function(numbers) {
  numbers <- (numbers - mean(numbers)) / sd(numbers)
  return(numbers)
}
minday_std <- standardized(minday)

# print the answer
cat("Original bookings datetime:", bookings$datetime[1:10], "...","\n")
cat("Standardized version(minday_std):", minday_std[1:10], "...")
```
<br>
i) What should we expect the mean and standard deviation of minday_std to be, and why?
- Answer: After standardized, the mean should be close to 0 and the sd should be close to 1.

```{r fig.width = 5, fig.height = 3.7}
cat("mean:", mean(minday_std), "\n")
cat("sd:", sd(minday_std))
```

ii) What should the distribution of minday_std look like compared to minday, and why?
- Answer: The curves look similar. However, the scales of x-axis and y-axis are totally different.
```{r fig.width = 5, fig.height = 3.7}
par(mfcol=c(1,2)) 
plot(density(minday), main="Minute (of the day) of first ever booking", col="blue", lwd=2)
plot(density(minday_std), main="(Standardized) Minute (of the day) of first ever booking", col="green", lwd=2)
```

Question 2) Copy and run the code we used in class to create simulations of confidence intervals. Run visualize_sample_ci(), which simulates samples drawn randomly from a population. Each sample is a horizontal line with a dark band for its 95% CI, and a lighter band for its 99% CI, and a dot for its mean. The population mean is a vertical black line. Samples whose 95% CI includes the population mean are blue, and others are red.
a) Simulate 100 samples (each of size 100), from a normally distributed population of 10,000:
visualize_sample_ci(num_samples = 100, sample_size = 100, pop_size=10000, 
                      distr_func=rnorm, mean=20, sd=3)
                      
```{r }
# Visualize the confidence intervals of samples drawn from a population
#   e.g.,
#     visualize_sample_ci(sample_size=300, distr_func=rnorm, mean=50, sd=10)
#     visualize_sample_ci(sample_size=300, distr_func=runif, min=17, max=35)

visualize_sample_ci <- function(num_samples = 100, sample_size = 100, pop_size=10000, FUN=rnorm, ...) {
  # Simulate a large population
  population_data <- FUN(pop_size, ...)
  pop_mean <- mean(population_data)
  pop_sd <- sd(population_data)
  
  # Simulate samples
  samples <- replicate(num_samples, 
                       sample(population_data, sample_size, replace=FALSE))
  
  # Calculate descriptives of samples
  sample_means = apply(samples, 2, FUN=mean)
  sample_stdevs = apply(samples, 2, FUN=sd)
  sample_stderrs <- sample_stdevs/sqrt(sample_size)
  ci95_low  <- sample_means - sample_stderrs*1.96
  ci95_high <- sample_means + sample_stderrs*1.96 
  ci99_low  <- sample_means - sample_stderrs*2.58
  ci99_high <- sample_means + sample_stderrs*2.58
  
  # Visualize confidence intervals of all samples
  plot(NULL, xlim=c(pop_mean-(pop_sd/2), pop_mean+(pop_sd/2)), 
       ylim=c(1,num_samples), ylab="Samples", xlab="Confidence Intervals")
  add_ci_segment(ci95_low, ci95_high, ci99_low, ci99_high,
                 sample_means, 1:num_samples, good=TRUE)
  
  # Visualize samples with CIs that don't include population mean
  bad = which(((ci95_low > pop_mean) | (ci95_high < pop_mean)) |
              ((ci99_low > pop_mean) | (ci99_high < pop_mean)))
  add_ci_segment(ci95_low[bad], ci95_high[bad], ci99_low[bad], ci99_high[bad],
                 sample_means[bad], bad, good=FALSE)
  
  # Draw true population mean
  abline(v=mean(population_data))
}

add_ci_segment <- function(ci95_low, ci95_high, ci99_low, ci99_high, 
                           sample_means, indices, good=TRUE) {
  segment_colors <- list(c("lightcoral", "coral3", "coral4"),
                         c("lightskyblue", "skyblue3", "skyblue4"))
  color <- segment_colors[[as.integer(good)+1]]
  
  segments(ci99_low, indices, ci99_high, indices, lwd=3, col=color[1])
  segments(ci95_low, indices, ci95_high, indices, lwd=3, col=color[2])
  points(sample_means, indices, pch=18, cex=0.6, col=color[3])
}
visualize_sample_ci(num_samples = 100, sample_size = 100, pop_size = 10000, FUN = rnorm, mean=20,sd=3)
```

i) How many samples do we expect to NOT include the population mean in its 95% CI?
- Answer: four (dark red line)
ii) How many samples do we expect to NOT include the population mean in their 99% CI?
- Answer: zero (light red line)

b) Rerun the previous simulation with larger samples (sample_size=300):
i) Now that the size of each sample has increased, do we expect their 95% and 99% CI to become wider or narrower than before?
```{r fig.width = 5, fig.height = 3.7}
visualize_sample_ci(num_samples = 100, sample_size = 300, pop_size=10000, FUN=rnorm, mean=20, sd=3)
```
-Answer: As the size of each sample has increased,the 95% and 99% CI become narrower than before.

ii) This time, how many samples (out of the 100) would we expect to NOT include the population mean in its 95% CI?
- Answer: seven (dark red line)

c) If we ran the above two examples (a and b) using a uniformly distributed population (specify distr_func=runif for visualize_sample_ci), how do you expect your answers to (a) and (b) to change, and why?

```{r fig.width = 5, fig.height = 3.7}
par(mfcol=c(1,2)) 
visualize_sample_ci(num_samples = 100, sample_size = 100, pop_size=10000, FUN=runif)
visualize_sample_ci(num_samples = 100, sample_size = 300, pop_size=10000, FUN=runif)
```
- Answer:
  - sample_size = 100, distr_func=runif
    - i) How many samples do we expect to NOT include the population mean in its 95% CI?
      - Answer: seven (dark red line)
    - ii) How many samples do we expect to NOT include the population mean in their 99% CI?
      - Answer: zero (light red line)
  - sample_size = 300, distr_func=runif
    - i) Now that the size of each sample has increased, do we expect their 95% and 99% CI to become wider or narrower than before?
      - Answer: As the size of each sample has increased,the 95% and 99% CI become narrower than before. The result is same as "rnorm".
    - ii) This time, how many samples (out of the 100) would we expect to NOT include the population mean in its 95% CI?
      - Answer: six (dark red line)


Question 3) The startup company EZTABLE has an online restaurant reservation system that is accessible by mobile and web. Imagine that EZTABLE would like to start a promotion for new members to make their bookings earlier in the day.

We have a sample of data about their new members, in particular the date and time for which they make their first ever booking (i.e., the booked time for the restaurant) using the EZTABLE platform. Here is some sample code to explore the data:

a) What is the “average” booking time for new members making their first restaurant booking?
(use minday, which is the absolute minute of the day from 0-1440)
i) Use traditional statistical methods to estimate the population mean of minday, its standard error, and the 95% confidence interval (CI) of the sampling means
```{r }
bookings <- read.table("first_bookings_datetime_sample.txt", header=TRUE)
# bookings$datetime[1:9]
hours  <- as.POSIXlt(bookings$datetime, format="%m/%d/%Y %H:%M")$hour
mins   <- as.POSIXlt(bookings$datetime, format="%m/%d/%Y %H:%M")$min
minday <- hours*60 + mins
# plot(density(minday), main="Minute (of the day) of first ever booking", col="blue", lwd=2)


# print the ans
cat("mean:", mean(minday), "\n")
cat("sd:", sd(minday), "\n")
cat("95% CI:", quantile(minday, probs=c(0.025, 0.975)))

```
<br>

ii) Bootstrap to produce 2000 new samples from the original sample
```{r fig.width = 5, fig.height = 3.7}
sample_size = 2000
sample0 = sample(minday, sample_size)
sample0_mean = mean(sample0)
cat("sample0:", print(sample0), "\n")
# cat("sample0_mean:", mean(sample0), "\n")

resamples <- replicate(2000, sample(sample0, length(sample0), replace=TRUE))
cat("resamples:", resamples)
# cat("resamples_mean:", mean(resamples))
```
<br>

iii) Visualize the means of the 2000 bootstrapped samples
```{r fig.width = 5, fig.height = 3.7}
# Create an empty plotting space with axes
plot(density(minday), lwd=0, ylim=c(0, 0.009), main="bootstrapped samples")

plot_resample_density <- function(sample_i) { 
  lines(density(sample_i), col=rgb(0.0, 0.4, 0.0, 0.01))
  return(mean(sample_i))
}
# Plot and get means of all bootstrapped samples
sample_means <- apply(resamples, 2, FUN=plot_resample_density)
# Plot hidden population and original sample distributions
lines(density(sample0), lwd=3) 
lines(density(minday), lwd=2, lty="dashed")
```
<br>

iv) Estimate the 95% CI of the bootstrapped means.
- Answer: 690-1200 
```{r }
quantile(resamples, probs=c(0.025, 0.975))
```

b) By what time of day, have half the new members of the day already arrived at their restaurant?
i) Estimate the median of minday
- Answer: 1040
```{r }
cat("median of minday:", median(minday))
```
<br>

ii) Visualize the medians of the 2000 bootstrapped samples
- Answer: Define a function called **get_median** to get each sample's median, and use **apply** to run the function 2000 times. In the end, we will get the **Histogram of median of resamples**.
```{r fig.width = 5, fig.height = 3.7}
get_median <- function(i){
  return(median(i))
}

median <- apply(resamples, 1, FUN=get_median)
hist(median, main="Histogram of median of resamples")
```
<br>
iii) Estimate the 95% CI of the bootstrapped medians.
- Answer: 960-1050 
```{r }
quantile(median, probs=c(0.025, 0.975))
```

